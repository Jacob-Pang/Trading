{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Bot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import TRANSACT_FEE_RATE, STOP_LOSS_RATE, TRAILING_RATE\n",
    "\n",
    "data_dpath = os.path.join(os.getcwd(), \"data\")\n",
    "os.chdir(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.market import MarketBase\n",
    "from src.market.bitfinex import BitfinexSpot\n",
    "from src.market_actor import MarketActorStub\n",
    "from src.market_listener import MarketListenerStub\n",
    "from src.advance_order.convertible_stop_loss import ConvertibleStopLoss\n",
    "\n",
    "market = BitfinexSpot(\"BTC\", \"USD\")\n",
    "market_actor = MarketActorStub(TRANSACT_FEE_RATE, echo_mode=False)\n",
    "market_listener = MarketListenerStub(market)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Pipeline Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(data_dpath, \"data_pipeline.pickle\"), \"rb\") as file:\n",
    "    data_pipeline = pickle.load(file)\n",
    "    \n",
    "    candle_buffers = data_pipeline.get(\"candle_buffers\")\n",
    "    features_compiler = data_pipeline.get(\"features_compiler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Candle History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bfxapi import Client\n",
    "\n",
    "async def get_candles(bfx: Client, market: MarketBase, epochs: int = 100,\n",
    "    frame_resolution: str = \"1m\") -> pd.DataFrame:\n",
    "\n",
    "    end = int(time.time())\n",
    "    end -= (end % 60) # Truncate to minutes\n",
    "    end *= 1000 # Convert to ms\n",
    "\n",
    "    candles = await asyncio.gather(*[\n",
    "        bfx.rest.get_public_candles(symbol=market.get_ticker(), start=0,\n",
    "                end=(end - epoch * 10000 * 60000), limit=10000, tf=frame_resolution)\n",
    "        for epoch in range(epochs)\n",
    "    ])\n",
    "\n",
    "    candles = pd.DataFrame(\n",
    "        np.concatenate(candles),\n",
    "        columns=[\"Timestamp\", \"Open\", \"Close\", \"High\", \"Low\", \"Volume\"]\n",
    "    )\n",
    "\n",
    "    candles[\"Timestamp\"] /= 1000 # Convert from ms to seconds\n",
    "    candles[\"Timestamp\"] = candles[\"Timestamp\"].astype(int)\n",
    "\n",
    "    return candles.set_index(\"Timestamp\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1668510780</th>\n",
       "      <td>16899.0</td>\n",
       "      <td>16884.0</td>\n",
       "      <td>16899.0</td>\n",
       "      <td>16879.0</td>\n",
       "      <td>0.181140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668510840</th>\n",
       "      <td>16879.0</td>\n",
       "      <td>16875.0</td>\n",
       "      <td>16881.0</td>\n",
       "      <td>16874.0</td>\n",
       "      <td>0.581965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668510900</th>\n",
       "      <td>16875.0</td>\n",
       "      <td>16866.0</td>\n",
       "      <td>16882.0</td>\n",
       "      <td>16866.0</td>\n",
       "      <td>10.222098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668510960</th>\n",
       "      <td>16866.0</td>\n",
       "      <td>16848.0</td>\n",
       "      <td>16866.0</td>\n",
       "      <td>16848.0</td>\n",
       "      <td>1.658221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668511020</th>\n",
       "      <td>16848.0</td>\n",
       "      <td>16762.0</td>\n",
       "      <td>16852.0</td>\n",
       "      <td>16752.0</td>\n",
       "      <td>87.184955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669113480</th>\n",
       "      <td>15733.0</td>\n",
       "      <td>15734.0</td>\n",
       "      <td>15735.0</td>\n",
       "      <td>15733.0</td>\n",
       "      <td>0.881324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669113540</th>\n",
       "      <td>15734.0</td>\n",
       "      <td>15723.0</td>\n",
       "      <td>15734.0</td>\n",
       "      <td>15723.0</td>\n",
       "      <td>0.321597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669113600</th>\n",
       "      <td>15723.0</td>\n",
       "      <td>15730.0</td>\n",
       "      <td>15731.0</td>\n",
       "      <td>15723.0</td>\n",
       "      <td>0.461327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669113660</th>\n",
       "      <td>15732.0</td>\n",
       "      <td>15737.0</td>\n",
       "      <td>15737.0</td>\n",
       "      <td>15731.0</td>\n",
       "      <td>0.617536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669113720</th>\n",
       "      <td>15734.0</td>\n",
       "      <td>15742.0</td>\n",
       "      <td>15742.0</td>\n",
       "      <td>15734.0</td>\n",
       "      <td>0.393857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open    Close     High      Low     Volume\n",
       "Timestamp                                                \n",
       "1668510780  16899.0  16884.0  16899.0  16879.0   0.181140\n",
       "1668510840  16879.0  16875.0  16881.0  16874.0   0.581965\n",
       "1668510900  16875.0  16866.0  16882.0  16866.0  10.222098\n",
       "1668510960  16866.0  16848.0  16866.0  16848.0   1.658221\n",
       "1668511020  16848.0  16762.0  16852.0  16752.0  87.184955\n",
       "...             ...      ...      ...      ...        ...\n",
       "1669113480  15733.0  15734.0  15735.0  15733.0   0.881324\n",
       "1669113540  15734.0  15723.0  15734.0  15723.0   0.321597\n",
       "1669113600  15723.0  15730.0  15731.0  15723.0   0.461327\n",
       "1669113660  15732.0  15737.0  15737.0  15731.0   0.617536\n",
       "1669113720  15734.0  15742.0  15742.0  15734.0   0.393857\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles = await get_candles(Client(), market, epochs=1)\n",
    "\n",
    "candles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.candle_buffer import CandleBuffer\n",
    "from src.indicator import FeaturesCompiler\n",
    "from src.tradebook import Tradebook\n",
    "\n",
    "def extract_observations(candle_buffers: dict[int, CandleBuffer], features_compiler: FeaturesCompiler,\n",
    "    candles: pd.DataFrame):\n",
    "\n",
    "    tradebook = Tradebook(10) # To facilitate update of orderbook\n",
    "    timestamps, observations = [], []\n",
    "\n",
    "    for timestamp, data in tqdm(list(candles.iterrows())):\n",
    "        ready = True\n",
    "        update_timestamp = timestamp - 1 # The passed timestamp denotes the end of time frame\n",
    "        tradebook.append_trade(update_timestamp, (data.get(\"Open\") + data.get(\"Close\")) / 2,\n",
    "                data.get(\"Volume\"))\n",
    "        \n",
    "        for candle_buffer in candle_buffers.values():\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Open\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"High\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Low\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Close\"), tradebook)\n",
    "\n",
    "            if ready: # Checks if the buffers have been fully populated\n",
    "                ready = (candle_buffer.get_size() == candle_buffer.get_capacity())\n",
    "        \n",
    "        if ready:\n",
    "            timestamps.append(timestamp)\n",
    "            observations.append(features_compiler.get())\n",
    "    \n",
    "    return np.array(timestamps, dtype=int), np.array(observations, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:37<00:00, 266.26it/s]\n"
     ]
    }
   ],
   "source": [
    "obs_timestamps, observations = extract_observations(candle_buffers, features_compiler, candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56, -0.56, -0.56, ..., -0.56, -0.56, -0.56])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to replace the observations for CryptoFearAndGreed: features[0]\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6 , -0.6 , -0.6 , ..., -0.56, -0.56, -0.56])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.indicator.fear_and_greed import CryptoFearAndGreed\n",
    "\n",
    "fng_timestamps, fng_values = CryptoFearAndGreed.get_hist_data()\n",
    "max_index = fng_timestamps.shape[0] - 1\n",
    "fng_index = 0\n",
    "\n",
    "for obs_index, timestamp in enumerate(obs_timestamps):\n",
    "    while (fng_index != max_index) and (timestamp > fng_timestamps[fng_index + 1]):\n",
    "        fng_index += 1\n",
    "\n",
    "    observations[obs_index, 0] = fng_values[fng_index]\n",
    "\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate Candles to Number of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = candles[-observations.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Outputs (Trading Signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_values = candles[\"Close\"].values\n",
    "high_values = candles[\"High\"].values\n",
    "low_values = candles[\"Low\"].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9085/10000 [00:34<00:03, 262.24it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.671436433681894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for long signals\n",
    "long_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=1)\n",
    "\n",
    "    advance_order = ConvertibleStopLoss(\n",
    "        position, market_actor, market_listener, close_values[open_timestamp],\n",
    "        STOP_LOSS_RATE, TRAILING_RATE, stop_loss_as_rate=True\n",
    "    )\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating low before high\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "\n",
    "    long_signals.append(int(advance_order.position.balances.get(\"USD\") > 0))\n",
    "\n",
    "long_signals = np.array(long_signals, dtype=int)\n",
    "np.sum(long_signals) / long_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9097/10000 [00:35<00:03, 257.50it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.059470154996156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for short signals\n",
    "short_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=-1)\n",
    "\n",
    "    advance_order = ConvertibleStopLoss(\n",
    "        position, market_actor, market_listener, close_values[open_timestamp],\n",
    "        STOP_LOSS_RATE, TRAILING_RATE, stop_loss_as_rate=True\n",
    "    )\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating high before low\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "\n",
    "    short_signals.append(int(advance_order.position.balances.get(\"USD\") > 0))\n",
    "\n",
    "short_signals = np.array(short_signals, dtype=int)\n",
    "np.sum(short_signals) / short_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_dpath, \"observations.npy\"), observations)\n",
    "np.save(os.path.join(data_dpath, \"long_signals.npy\"), long_signals)\n",
    "np.save(os.path.join(data_dpath, \"short_signals.npy\"), short_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90d99a365a6800d6d3b874802d775db992b69c47481bfc65e12294d647a46c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
