{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Bot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import TRANSACT_FEE_RATE, STOP_LOSS_RATE, TRAILING_RATE\n",
    "\n",
    "data_dpath = os.path.join(os.getcwd(), \"data\")\n",
    "os.chdir(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.market import MarketBase\n",
    "from src.market.bitfinex import BitfinexSpot\n",
    "from src.market_actor import MarketActorStub\n",
    "from src.market_listener import MarketListenerStub\n",
    "from src.advance_order.convertible_stop_loss import ConvertibleStopLoss\n",
    "\n",
    "market = BitfinexSpot(\"BTC\", \"USD\")\n",
    "market_actor = MarketActorStub(TRANSACT_FEE_RATE, echo_mode=False)\n",
    "market_listener = MarketListenerStub(market)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Pipeline Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(data_dpath, \"data_pipeline.pickle\"), \"rb\") as file:\n",
    "    data_pipeline = pickle.load(file)\n",
    "    \n",
    "    candle_buffers = data_pipeline.get(\"candle_buffers\")\n",
    "    features_compiler = data_pipeline.get(\"features_compiler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Candle History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bfxapi import Client\n",
    "\n",
    "async def get_candles(bfx: Client, market: MarketBase, epochs: int = 100,\n",
    "    frame_resolution: str = \"1m\") -> pd.DataFrame:\n",
    "\n",
    "    end = int(time.time())\n",
    "    end -= (end % 60) # Truncate to minutes\n",
    "    end *= 1000 # Convert to ms\n",
    "\n",
    "    candles = await asyncio.gather(*[\n",
    "        bfx.rest.get_public_candles(symbol=market.get_ticker(), start=0,\n",
    "                end=(end - epoch * 10000 * 60000), limit=10000, tf=frame_resolution)\n",
    "        for epoch in range(epochs)\n",
    "    ])\n",
    "\n",
    "    candles = pd.DataFrame(\n",
    "        np.concatenate(candles),\n",
    "        columns=[\"Timestamp\", \"Open\", \"Close\", \"High\", \"Low\", \"Volume\"]\n",
    "    )\n",
    "\n",
    "    candles[\"Timestamp\"] /= 1000 # Convert from ms to seconds\n",
    "    candles[\"Timestamp\"] = candles[\"Timestamp\"].astype(int)\n",
    "\n",
    "    return candles.set_index(\"Timestamp\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1668580440</th>\n",
       "      <td>16819.0</td>\n",
       "      <td>16817.0</td>\n",
       "      <td>16820.0</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>3.552167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668580500</th>\n",
       "      <td>16814.0</td>\n",
       "      <td>16811.0</td>\n",
       "      <td>16818.0</td>\n",
       "      <td>16811.0</td>\n",
       "      <td>3.672976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668580560</th>\n",
       "      <td>16810.0</td>\n",
       "      <td>16799.0</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>16798.0</td>\n",
       "      <td>6.654021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668580620</th>\n",
       "      <td>16800.0</td>\n",
       "      <td>16814.0</td>\n",
       "      <td>16814.0</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>3.114102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668580680</th>\n",
       "      <td>16814.0</td>\n",
       "      <td>16828.0</td>\n",
       "      <td>16828.0</td>\n",
       "      <td>16814.0</td>\n",
       "      <td>3.258646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669183140</th>\n",
       "      <td>16458.0</td>\n",
       "      <td>16463.0</td>\n",
       "      <td>16466.0</td>\n",
       "      <td>16458.0</td>\n",
       "      <td>2.937683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669183200</th>\n",
       "      <td>16462.0</td>\n",
       "      <td>16469.0</td>\n",
       "      <td>16469.0</td>\n",
       "      <td>16462.0</td>\n",
       "      <td>1.087184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669183260</th>\n",
       "      <td>16474.0</td>\n",
       "      <td>16475.0</td>\n",
       "      <td>16475.0</td>\n",
       "      <td>16473.0</td>\n",
       "      <td>0.671472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669183320</th>\n",
       "      <td>16475.0</td>\n",
       "      <td>16472.0</td>\n",
       "      <td>16476.0</td>\n",
       "      <td>16472.0</td>\n",
       "      <td>5.760059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669183380</th>\n",
       "      <td>16473.0</td>\n",
       "      <td>16472.0</td>\n",
       "      <td>16473.0</td>\n",
       "      <td>16471.0</td>\n",
       "      <td>2.006532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open    Close     High      Low    Volume\n",
       "Timestamp                                               \n",
       "1668580440  16819.0  16817.0  16820.0  16810.0  3.552167\n",
       "1668580500  16814.0  16811.0  16818.0  16811.0  3.672976\n",
       "1668580560  16810.0  16799.0  16810.0  16798.0  6.654021\n",
       "1668580620  16800.0  16814.0  16814.0  16800.0  3.114102\n",
       "1668580680  16814.0  16828.0  16828.0  16814.0  3.258646\n",
       "...             ...      ...      ...      ...       ...\n",
       "1669183140  16458.0  16463.0  16466.0  16458.0  2.937683\n",
       "1669183200  16462.0  16469.0  16469.0  16462.0  1.087184\n",
       "1669183260  16474.0  16475.0  16475.0  16473.0  0.671472\n",
       "1669183320  16475.0  16472.0  16476.0  16472.0  5.760059\n",
       "1669183380  16473.0  16472.0  16473.0  16471.0  2.006532\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles = await get_candles(Client(), market, epochs=300)\n",
    "\n",
    "candles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.candle_buffer import CandleBuffer\n",
    "from src.indicator import FeaturesCompiler\n",
    "from src.tradebook import Tradebook\n",
    "\n",
    "def extract_observations(candle_buffers: dict[int, CandleBuffer], features_compiler: FeaturesCompiler,\n",
    "    candles: pd.DataFrame):\n",
    "    global true_x, obs_x, obs_y\n",
    "    tradebook = Tradebook(10) # To facilitate update of orderbook\n",
    "    timestamps, observations = [], []\n",
    "    buffer_ready = False\n",
    "\n",
    "    for timestamp, data in tqdm(list(candles.iterrows())):\n",
    "        update_timestamp = timestamp - 1 # The passed timestamp denotes the end of time frame\n",
    "        tradebook.append_trade(update_timestamp, (data.get(\"Open\") + data.get(\"Close\")) / 2,\n",
    "                data.get(\"Volume\"))\n",
    "        \n",
    "        for candle_buffer in candle_buffers.values():\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Open\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"High\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Low\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Close\"), tradebook)\n",
    "\n",
    "        if not buffer_ready:\n",
    "            for candle_buffer in candle_buffers.values():\n",
    "                buffer_ready = (candle_buffer.get_size() == candle_buffer.get_capacity())\n",
    "                if not buffer_ready: break\n",
    "                \n",
    "        if buffer_ready:\n",
    "            timestamps.append(timestamp)\n",
    "            observations.append(features_compiler.get().copy()) # Create a copy from the memoryview\n",
    "    \n",
    "    return np.array(timestamps, dtype=int), np.array(observations, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:38<00:00, 259.18it/s]\n"
     ]
    }
   ],
   "source": [
    "obs_timestamps, observations = extract_observations(candle_buffers, features_compiler, candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56, -0.56, -0.56, ..., -0.56, -0.56, -0.56])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to replace the observations for CryptoFearAndGreed: features[0]\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54, -0.54, -0.54, ..., -0.56, -0.56, -0.56])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.indicator.fear_and_greed import CryptoFearAndGreed\n",
    "\n",
    "fng_timestamps, fng_values = CryptoFearAndGreed.get_hist_data()\n",
    "max_index = fng_timestamps.shape[0] - 1\n",
    "fng_index = 0\n",
    "\n",
    "for obs_index, timestamp in enumerate(obs_timestamps):\n",
    "    while (fng_index != max_index) and (timestamp > fng_timestamps[fng_index + 1]):\n",
    "        fng_index += 1\n",
    "\n",
    "    observations[obs_index, 0] = fng_values[fng_index]\n",
    "\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate Candles to Number of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = candles[-observations.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Outputs (Trading Signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_values = candles[\"Close\"].values\n",
    "high_values = candles[\"High\"].values\n",
    "low_values = candles[\"Low\"].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6907/7095 [00:09<00:00, 740.52it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.592152888374113"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for long signals\n",
    "long_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=1)\n",
    "\n",
    "    advance_order = ConvertibleStopLoss(\n",
    "        position, market_actor, market_listener, close_values[open_timestamp],\n",
    "        STOP_LOSS_RATE, TRAILING_RATE, stop_loss_as_rate=True\n",
    "    )\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating low before high\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "\n",
    "    long_signals.append(int(advance_order.position.balances.get(\"USD\") > 0))\n",
    "\n",
    "long_signals = np.array(long_signals, dtype=int)\n",
    "np.sum(long_signals) / long_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6878/7095 [00:10<00:00, 661.21it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.656586216923525"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for short signals\n",
    "short_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=-1)\n",
    "\n",
    "    advance_order = ConvertibleStopLoss(\n",
    "        position, market_actor, market_listener, close_values[open_timestamp],\n",
    "        STOP_LOSS_RATE, TRAILING_RATE, stop_loss_as_rate=True\n",
    "    )\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating high before low\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "\n",
    "    short_signals.append(int(advance_order.position.balances.get(\"USD\") > 0))\n",
    "\n",
    "short_signals = np.array(short_signals, dtype=int)\n",
    "np.sum(short_signals) / short_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_dpath, \"observations.npy\"), observations)\n",
    "np.save(os.path.join(data_dpath, \"long_signals.npy\"), long_signals)\n",
    "np.save(os.path.join(data_dpath, \"short_signals.npy\"), short_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90d99a365a6800d6d3b874802d775db992b69c47481bfc65e12294d647a46c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
