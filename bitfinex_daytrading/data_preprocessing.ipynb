{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Bot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import TRANSACT_FEE_RATE, STOP_LOSS_RATE, TRAILING_RATE\n",
    "\n",
    "DATA_DPATH = os.path.join(os.getcwd(), \"data\")\n",
    "os.chdir(os.path.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.market import MarketBase\n",
    "from src.market.bitfinex import BitfinexSpot\n",
    "from src.market_actor import MarketActorStub\n",
    "from src.market_listener import MarketListenerStub\n",
    "from src.advance_order.convertible_stop_loss import ConvertibleStopLossLogic\n",
    "\n",
    "market = BitfinexSpot(\"BTC\", \"USD\")\n",
    "market_actor = MarketActorStub(TRANSACT_FEE_RATE, echo_mode=False)\n",
    "market_listener = MarketListenerStub(market)\n",
    "advance_order_logic = ConvertibleStopLossLogic(market_actor, market_listener,\n",
    "        STOP_LOSS_RATE, trailing_rate=TRAILING_RATE, offset_as_rate=True,\n",
    "        use_orderbook=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Pipeline Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(DATA_DPATH, \"data_pipeline.pickle\"), \"rb\") as file:\n",
    "    data_pipeline = pickle.load(file)\n",
    "    \n",
    "    candle_buffers = data_pipeline.get(\"candle_buffers\")\n",
    "    features_compiler = data_pipeline.get(\"features_compiler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Candle History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bfxapi import Client\n",
    "\n",
    "async def get_candles(bfx: Client, market: MarketBase, epochs: int = 100,\n",
    "    frame_resolution: str = \"1m\") -> pd.DataFrame:\n",
    "\n",
    "    end = int(time.time())\n",
    "    end -= (end % 60) # Truncate to minutes\n",
    "    end *= 1000 # Convert to ms\n",
    "\n",
    "    candles = await asyncio.gather(*[\n",
    "        bfx.rest.get_public_candles(symbol=market.get_ticker(), start=0,\n",
    "                end=(end - epoch * 10000 * 60000), limit=10000, tf=frame_resolution)\n",
    "        for epoch in range(epochs)\n",
    "    ])\n",
    "\n",
    "    candles = pd.DataFrame(\n",
    "        np.concatenate(candles),\n",
    "        columns=[\"Timestamp\", \"Open\", \"Close\", \"High\", \"Low\", \"Volume\"]\n",
    "    )\n",
    "\n",
    "    candles[\"Timestamp\"] /= 1000 # Convert from ms to seconds\n",
    "    candles[\"Timestamp\"] = candles[\"Timestamp\"].astype(int)\n",
    "\n",
    "    return candles.set_index(\"Timestamp\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1668790620</th>\n",
       "      <td>16650.0</td>\n",
       "      <td>16641.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>16641.0</td>\n",
       "      <td>0.007074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668790680</th>\n",
       "      <td>16642.0</td>\n",
       "      <td>16641.0</td>\n",
       "      <td>16642.0</td>\n",
       "      <td>16636.0</td>\n",
       "      <td>0.021766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668790740</th>\n",
       "      <td>16641.0</td>\n",
       "      <td>16642.0</td>\n",
       "      <td>16644.0</td>\n",
       "      <td>16641.0</td>\n",
       "      <td>0.051292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668790800</th>\n",
       "      <td>16642.0</td>\n",
       "      <td>16644.0</td>\n",
       "      <td>16644.0</td>\n",
       "      <td>16641.0</td>\n",
       "      <td>0.065620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668790860</th>\n",
       "      <td>16651.0</td>\n",
       "      <td>16652.0</td>\n",
       "      <td>16652.0</td>\n",
       "      <td>16651.0</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669393200</th>\n",
       "      <td>16492.0</td>\n",
       "      <td>16481.0</td>\n",
       "      <td>16492.0</td>\n",
       "      <td>16481.0</td>\n",
       "      <td>0.108947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669393260</th>\n",
       "      <td>16480.0</td>\n",
       "      <td>16468.0</td>\n",
       "      <td>16480.0</td>\n",
       "      <td>16468.0</td>\n",
       "      <td>1.311781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669393320</th>\n",
       "      <td>16468.0</td>\n",
       "      <td>16468.0</td>\n",
       "      <td>16469.0</td>\n",
       "      <td>16465.0</td>\n",
       "      <td>2.563234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669393380</th>\n",
       "      <td>16468.0</td>\n",
       "      <td>16467.0</td>\n",
       "      <td>16470.0</td>\n",
       "      <td>16467.0</td>\n",
       "      <td>0.039476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669393440</th>\n",
       "      <td>16467.0</td>\n",
       "      <td>16472.0</td>\n",
       "      <td>16473.0</td>\n",
       "      <td>16467.0</td>\n",
       "      <td>1.404438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open    Close     High      Low    Volume\n",
       "Timestamp                                               \n",
       "1668790620  16650.0  16641.0  16650.0  16641.0  0.007074\n",
       "1668790680  16642.0  16641.0  16642.0  16636.0  0.021766\n",
       "1668790740  16641.0  16642.0  16644.0  16641.0  0.051292\n",
       "1668790800  16642.0  16644.0  16644.0  16641.0  0.065620\n",
       "1668790860  16651.0  16652.0  16652.0  16651.0  0.025000\n",
       "...             ...      ...      ...      ...       ...\n",
       "1669393200  16492.0  16481.0  16492.0  16481.0  0.108947\n",
       "1669393260  16480.0  16468.0  16480.0  16468.0  1.311781\n",
       "1669393320  16468.0  16468.0  16469.0  16465.0  2.563234\n",
       "1669393380  16468.0  16467.0  16470.0  16467.0  0.039476\n",
       "1669393440  16467.0  16472.0  16473.0  16467.0  1.404438\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles = await get_candles(Client(), market, epochs=1)\n",
    "\n",
    "candles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.candle_buffer import CandleBuffer\n",
    "from src.indicator import FeaturesCompiler\n",
    "from src.tradebook import Tradebook\n",
    "\n",
    "def extract_observations(candle_buffers: dict[int, CandleBuffer], features_compiler: FeaturesCompiler,\n",
    "    candles: pd.DataFrame):\n",
    "    global true_x, obs_x, obs_y\n",
    "    tradebook = Tradebook(10) # To facilitate update of orderbook\n",
    "    timestamps, observations = [], []\n",
    "    buffer_ready = False\n",
    "\n",
    "    for timestamp, data in tqdm(list(candles.iterrows())):\n",
    "        update_timestamp = timestamp - 1 # The passed timestamp denotes the end of time frame\n",
    "        tradebook.append_trade(update_timestamp, (data.get(\"Open\") + data.get(\"Close\")) / 2,\n",
    "                data.get(\"Volume\"))\n",
    "        \n",
    "        for candle_buffer in candle_buffers.values():\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Open\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"High\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Low\"), tradebook)\n",
    "            candle_buffer.update(update_timestamp, data.get(\"Close\"), tradebook)\n",
    "\n",
    "        if not buffer_ready:\n",
    "            for candle_buffer in candle_buffers.values():\n",
    "                buffer_ready = (candle_buffer.get_size() == candle_buffer.get_capacity())\n",
    "                if not buffer_ready: break\n",
    "                \n",
    "        if buffer_ready:\n",
    "            timestamps.append(timestamp)\n",
    "            observations.append(features_compiler.get().copy()) # Create a copy from the memoryview\n",
    "    \n",
    "    return np.array(timestamps, dtype=int), np.array(observations, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:36<00:00, 271.96it/s]\n"
     ]
    }
   ],
   "source": [
    "obs_timestamps, observations = extract_observations(candle_buffers, features_compiler, candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6, -0.6, -0.6, ..., -0.6, -0.6, -0.6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to replace the observations for CryptoFearAndGreed: features[0]\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52, -0.52, -0.52, ..., -0.6 , -0.6 , -0.6 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.indicator.fear_and_greed import CryptoFearAndGreed\n",
    "\n",
    "fng_timestamps, fng_values = CryptoFearAndGreed.get_hist_data()\n",
    "max_index = fng_timestamps.shape[0] - 1\n",
    "fng_index = 0\n",
    "\n",
    "for obs_index, timestamp in enumerate(obs_timestamps):\n",
    "    while (fng_index != max_index) and (timestamp > fng_timestamps[fng_index + 1]):\n",
    "        fng_index += 1\n",
    "\n",
    "    observations[obs_index, 0] = fng_values[fng_index]\n",
    "\n",
    "observations[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate Candles to Number of Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = candles[-observations.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Outputs (Trading Signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_values = candles[\"Close\"].values\n",
    "high_values = candles[\"High\"].values\n",
    "low_values = candles[\"Low\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 6299/7163 [00:05<00:00, 1174.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.14684870614383"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for long signals\n",
    "long_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=1)\n",
    "    advance_order = advance_order_logic.open_advance_order(position)\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating low before high\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "\n",
    "    long_signals.append(int(advance_order.position.balances.get_size(\"USD\") > 0))\n",
    "\n",
    "long_signals = np.array(long_signals, dtype=int)\n",
    "np.sum(long_signals) / long_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 6457/7163 [00:06<00:00, 1024.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.334985287285114"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate for short signals\n",
    "short_signals = []\n",
    "\n",
    "for open_timestamp in tqdm(range(close_values.shape[0])):\n",
    "    position = market_actor.open_position(market, close_values[open_timestamp], size=-1)\n",
    "    advance_order = advance_order_logic.open_advance_order(position)\n",
    "\n",
    "    for timestamp in range(open_timestamp + 1, close_values.shape[0]):\n",
    "        # Simulate unfavourable development by updating high before low\n",
    "        market_listener.set_current_price(high_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(low_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        market_listener.set_current_price(close_values[timestamp])\n",
    "        advance_order.update()\n",
    "\n",
    "        if advance_order.filled:\n",
    "            break\n",
    "    \n",
    "    if not advance_order.filled:\n",
    "        break\n",
    "    \n",
    "    short_signals.append(int(advance_order.position.balances.get_size(\"USD\") > 0))\n",
    "\n",
    "short_signals = np.array(short_signals, dtype=int)\n",
    "np.sum(short_signals) / short_signals.shape[0] * 100 # Percentage of signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(DATA_DPATH, \"observations.npy\"), observations)\n",
    "np.save(os.path.join(DATA_DPATH, \"long_signals.npy\"), long_signals)\n",
    "np.save(os.path.join(DATA_DPATH, \"short_signals.npy\"), short_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90d99a365a6800d6d3b874802d775db992b69c47481bfc65e12294d647a46c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
